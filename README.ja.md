# 伝文マクロ  

English version available: [README.md](./README.md)
  

## 概要
**伝文マクロ** は、人間とAIの両方が読解可能な構造で議論履歴を記録する「伝文マクロ」形式です。  
ChatGPT、Gemini、Claude など複数のAI間で文脈や履歴を共有し、議論の継続・検証を可能にすることを目指しています。  
現状ではchatGPT plus以上のプランを契約している方が利用できるchatGPT-4 TURBO以上のバージョンのみ使用できます。

## 利用目的
- 異なるAI間で議論の文脈を共有・再利用する
- ファクトチェックや多視点比較を容易にする
- LLM（大規模言語モデル）の文脈理解能力を評価・強化する
- スレッドが途中で停止した場合でも、手動バックアップとして機能する  
    chatGPTに伝文マクロを登録すれば「ここまでのやり取りを伝文マクロで記録」というプロンプトを打てば簡単にバックアップが取れる  
- ユーザーが伝文マクロの世代バックアップを保存しておけば、過去の任意の時点にさかのぼって議論を再開できる  
  テキスト形式なので、簡単に世代バックアップが取れ、AIがハルシネーションを起こした場合も安心
- ChatGPT同士であれば、スレッド間の移動や、バージョンの違いを越えた文脈の再利用が可能となる

## ディレクトリ構成
- `format_spec/` : Markdown / JSON / YAML形式のテンプレート
- `examples/` : 実際に使用された伝文マクロの例
- `LICENSE` : ライセンス情報（MIT）

## ChatGPTでの最初の使い方
以下の形式で新規スレッドの最初にChatGPTに入力します：
~~~
以下のデーター構造を伝文マクロと定義します。伝文マクロは多層化が可能です。伝文マクロをメモリーに記入してください。

#伝文_ラベル:{
  セクション名:{
    論点1=内容;
    論点2=内容;
  };
}
~~~
新規スレッドの最初に打たないと定義できません。  
chatGPTはこういうスレッドの事を「定義スレッド」と呼んでいるようです。


### ⚠️ 各AIでの使い方の違いについて
📘 ChatGPT や Gemini での伝文マクロの使い方（詳細）:  
→ [docs/usage.ja.md](./docs/usage.ja.md)
- **ChatGPT（GPT-4）**  
  - スレッド開始時またはメモリに伝文マクロを貼り付ける  
  - 必要に応じて「この伝文マクロをメモリーに記録してください」と指示する  

- **Gemini（2.5 Flashで実証済）**  
  - 「**設定とヘルプ**」から「**保存するよう Gemini にリクエストした情報**」に伝文マクロを登録するのが一番早いです。
    詳しくは上のリンク先を参照してください。  

実際のやり取り例：  
[Geminiの出力結果（共有リンク）](https://g.co/gemini/share/ce95067b8c52)

## 伝文マクロは誰でも使えますか？

はい、ChatGPT（特にGPT-4 Turbo）を使っていれば、誰でも伝文マクロ形式をプロンプトに貼り付けて使用できます。

既に上記の方法で伝文マクロをchatGPTのメモリーに記録してあれば、伝文マクロでchatGPTの対話を保存したいときには以下のようにプロンプトを打ちます。：

~~~
このスレッドの内容を伝文マクロでまとめてください。
~~~
簡単でしょ？  
  
バックアップ目的なら出力された伝文マクロをテキストエディタに記録して、そのままchatGPTとのやり取りを続けられます。  
  
もし、chatGPTがハルシネーションなどを起こし継続が困難になったら、新規スレッドにバックアップした伝文マクロを貼り「この話題の続きがしたいです」などとプロンプトを打てば続きから対話ができます。  
また伝文マクロの内容を新規スレッドが理解したか確認したい場合は「この伝文マクロからあなた(chatGPT)が理解した内容を表示してください」などとプロンプトを打って内容を確認できます。  

そして、このデータ構造テキスト（伝文マクロ）を他のスレッドに貼り

- 「この伝文マクロの続きをお願いします」
- 「要点だけ抜き出して」
- 「この構造で別の話題を整理して」

などの形でプロンプトを追加してください。  
伝文マクロを定義してしまえば、「このスレッドを伝文マクロ形式で記録」とバックアップを作ることができます。  
[例１ AGIの議論の伝文マクロ](./examples/AGI_discussion.ja.md)  
[例２ CANインベーダー攻撃防御の議論の伝文マクロ](./examples/canbus_security.ja.md)  
[例３ ChatGPT, Gemini, Claudeの回答差異を検証する伝文マクロ](./examples/factcheck_example.ja.md)  

スレッドがハルシネーションなどで途切れても、マクロさえ保存しておけば新しいスレッドで再現が可能です。  


### また、親スレッドと子スレッドの構造も簡単に作成できます。

1. 親スレッドでは、メインの話題だけを扱いましょう。
2. そこから派生した議論は、親スレッドにここまでの議論の内容を伝文マクロにしてと依頼しましょう。
3. 子スレッドを立てるときは、その伝文マクロを最初に貼り付けて、続きの議論を始めます。
4. 子スレッドの議論が終わったら、今度は親スレッド向けの伝文マクロを生成し、親スレッドに貼り付けます。

これにより、親子スレッドを伝文マクロで明確に接続できるようになります。

- 子スレッドはいくつでも作成できます。
- さらに、孫スレッド、ひ孫スレッドと階層的に構造を分けることも可能です。

  
## 将来的な目標：他AIとの互換性
将来的には、Gemini や Claude など他のAIチャットでも、プロンプトの先頭に伝文マクロを貼ることで、過去スレッドの再現や文脈継承ができるようになることを目指しています。  
この夢が実現できれば各AIをまたいで議論の続きができることになります。ファクトチェックも簡単になります。  

## 🚀 クロスAI対応の進展

2025年5月時点で、**Gemini 2.5 Flash** が伝文マクロを正しく解釈し、活用できることが確認されました。実際に以下のことが可能でした：

- 伝文マクロの構造を正確に解析
- 内容を人間向けに要約
- 論点に沿ったステップバイステップのロードマップを提示

使用した伝文マクロは以下のものでした：  
📄 [examples/AGI_discussion.ja.md](./examples/AGI_discussion.ja.md)

Geminiによる実際の出力はこちらで確認できます：  
🌐 [Gemini 2.5 Flash の出力結果（共有リンク）](https://g.co/gemini/share/ce95067b8c52)

この結果により、**CrossAI**構想が現実に機能することが実証されました。

🧠 また、2025年5月の追加検証により、Gemini 2.5 Flash でも内部メモリを持ち、明確に構造化された伝文マクロをメモリーに定義することで伝文マクロの読み込み書き出しが可能。セッションを超えた議論の再開が可能であることが確認されました。

⚠ 注意：Geminiは「覚えました」と応答することがありますが、セッションをまたぐ永続的な記憶とは限らないようです。
確実に伝文マクロを認識させるには、「**設定とヘルプ**」から「**保存するよう Gemini にリクエストした情報**」に伝文マクロを登録するのを推進します。(2025年5月15日追記)
  

## 貢献とライセンス
このプロジェクトは自由に使用・改変・再配布できます。  
ライセンス: MIT License
